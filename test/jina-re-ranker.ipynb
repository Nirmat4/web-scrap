{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17c6b758",
   "metadata": {},
   "source": [
    "#### Pruebas y analisis de la Generacion de JINA\n",
    "En este apartado del codigo se da una breve explicacion del funcionamiento del modelo Jina en su version \"jina-re-ranker-m0\"\n",
    "\n",
    "Los ejemplos son adaptaciones de los ejemplos proporcionados por la cuenta oficial de Jina en Hugginface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c468f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model = AutoModel.from_pretrained(\n",
    "    '../models/jina-reranker-m0',\n",
    "    torch_dtype=dtype,\n",
    "    local_files_only=True,\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda7ba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de ejecucion y funcionamiento de Jina con imagenes\n",
    "query = \"slm markdown\"\n",
    "documents = [\n",
    "    \"https://raw.githubusercontent.com/jina-ai/multimodal-reranker-test/main/handelsblatt-preview.png\",\n",
    "    # El contenido de esta pagina tiene la palabra \"markdown\" justamente compatible con el query\n",
    "    \"https://raw.githubusercontent.com/jina-ai/multimodal-reranker-test/main/paper-11.png\",\n",
    "    \"https://raw.githubusercontent.com/jina-ai/multimodal-reranker-test/main/wired-preview.png\",\n",
    "    \"https://jina.ai/blog-banner/using-deepseek-r1-reasoning-model-in-deepsearch.webp\"\n",
    "]\n",
    "\n",
    "# Creamos los pares, documento y query\n",
    "image_pairs = [[query, doc] for doc in documents]\n",
    "\n",
    "scores = model.compute_score(image_pairs, max_length=2048, doc_type=\"image\")\n",
    "# [0.49375027418136597, 0.7889736890792847, 0.47813892364501953, 0.5210812091827393]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928e36d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de ejecucion y funcionamiento de Jina con multilenguaje\n",
    "query = \"slm markdown\"\n",
    "documents = [\n",
    "    # Como se puede ver el primer documento contiene directamente la palabra \"markdown\"\n",
    "    \"We present ReaderLM-v2, a compact 1.5 billion parameter language model designed for efficient web content extraction. Our model processes documents up to 512K tokens, transforming messy HTML into clean Markdown or JSON formats with high accuracy -- making it an ideal tool for grounding large language models. The models effectiveness results from two key innovations: (1) a three-stage data synthesis pipeline that generates high quality, diverse training data by iteratively drafting, refining, and critiquing web content extraction; and (2) a unified training framework combining continuous pre-training with multi-objective optimization. Intensive evaluation demonstrates that ReaderLM-v2 outperforms GPT-4o-2024-08-06 and other larger models by 15-20% on carefully curated benchmarks, particularly excelling at documents exceeding 100K tokens, while maintaining significantly lower computational requirements.\",\n",
    "    \"数据提取么？为什么不用正则啊，你用正则不就全解决了么？\",\n",
    "    \"During the California Gold Rush, some merchants made more money selling supplies to miners than the miners made finding gold.\",\n",
    "    \"Die wichtigsten Beiträge unserer Arbeit sind zweifach: Erstens führen wir eine neuartige dreistufige Datensynthese-Pipeline namens Draft-Refine-Critique ein, die durch iterative Verfeinerung hochwertige Trainingsdaten generiert; und zweitens schlagen wir eine umfassende Trainingsstrategie vor, die kontinuierliches Vortraining zur Längenerweiterung, überwachtes Feintuning mit spezialisierten Kontrollpunkten, direkte Präferenzoptimierung (DPO) und iteratives Self-Play-Tuning kombiniert. Um die weitere Forschung und Anwendung der strukturierten Inhaltsextraktion zu erleichtern, ist das Modell auf Hugging Face öffentlich verfügbar.\",\n",
    "]\n",
    "\n",
    "# Creamos los pares, documento y query\n",
    "text_pairs = [[query, doc] for doc in documents]\n",
    "\n",
    "scores = model.compute_score(text_pairs, max_length=1024, doc_type=\"text\")\n",
    "# [0.6839263439178467, 0.4432148039340973, 0.5904013514518738, 0.45481112599372864]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527cf3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de ejecucion y funcionamiento de Jina con multiples imagienes entrada salida\n",
    "query = \"https://raw.githubusercontent.com/jina-ai/multimodal-reranker-test/main/paper-11.png\"\n",
    "\n",
    "documents = [\n",
    "    \"https://raw.githubusercontent.com/jina-ai/multimodal-reranker-test/main/handelsblatt-preview.png\",\n",
    "    # Como podemos notar es practicamente la misma imagen de entrada\n",
    "    \"https://raw.githubusercontent.com/jina-ai/multimodal-reranker-test/main/paper-11.png\",\n",
    "    \"https://raw.githubusercontent.com/jina-ai/multimodal-reranker-test/main/wired-preview.png\",\n",
    "    \"https://jina.ai/blog-banner/using-deepseek-r1-reasoning-model-in-deepsearch.webp\"\n",
    "]\n",
    "\n",
    "image_pairs = [[query, doc] for doc in documents]\n",
    "scores = model.compute_score(image_pairs, max_length=2048, doc_type=\"image\", query_type='image')\n",
    "# [0.6275860667228699, 0.9922324419021606, 0.8090347051620483, 0.7941296100616455]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
